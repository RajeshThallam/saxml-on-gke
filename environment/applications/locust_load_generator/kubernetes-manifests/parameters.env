SAX_CELL=/sax/test
TEST_ID_PREFIX=llama7b-benchmark
SAX_ROOT=gs://jk-saxml-admin-bucket/sax-root
KSA=saxml-sa
MODEL_REPOSITORY_BUCKET=jk-saxml-model-repository
MODEL_ID=/sax/test/llama7bfp16tpuv5e
TOKENIZER=meta-llama/Llama-2-7b-hf
TPU_TYPE=tpu-v4-podslice
TPU_TOPOLOGY=2x2x1
TEST_DATA=/model_repository/benchmarking/test_data/orca_prompts.jsonl
OUTPUT_LOCATION=/model_repository/benchmarking/test_runs
NUM_BATCHES=512
BATCH_SIZE=1
NUM_THREADS=1
PER_EXAMPLE_DECODE_STEPS=128
NUM_LOCUST_WORKERS=1
LOCUST_FILE=/app/dummy.py